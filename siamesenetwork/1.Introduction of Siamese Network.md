### Introduction of Siamese Network

#### 1. 基本摘要点

1. 相同权重
2. 两个不同的输入向量
3. 计算可比较的(类似的)输出向量
4. 通常其中一个输出向量是预计算的，因此作为一个标准(baseline)，这样另外一个输出可以与之进行比较

#### 2. 应用场景

1. 手写支票识别
2. 自动人脸监测
3. 索引围挡的匹配查询
4. 人脸识别

#### 3. 学习过程

1. 损失函数采用

   1. triplet loss

      $L=max(d(a,p)-d(a,n)+m,0),其中d是一个距离函数(比如L_2损失),a是数据集上的样本,p是一个随机正样本,n是一个随机负样本，m是一个任意的margin值，用来针对未来的正分数和负分数的分割进行调整的$

   2. contrastive loss

      $L=\frac{1}{2N}\sum_{n=1}^Nyd^2+(1-y)max(margin-d,0)^2$

   3. 二进制交叉熵损失

      $L=-ylog_{10}^p+(1-y)log_{10}^{1-p}$,$其中L是损失函数，y是标签(0或1)，p是预测值$

      $L=L_++L_-$

   4. 其他损失函数

2. 为了通过triplet loss来进行网络学习, 一个基准向量(baseline vector/anchor vector)用来和正样本向量(真实图像)和负样本向量(虚假图像)进行比较。负样本向量会强制在网络中学习，正样本向量会作为一个regularizer。

3. 为了通过contrastive loss来进行网络学习，必须有一个权重衰减(weight decay)策略来调整权重(regularize the weights)。

4. 如何选择损失函数的距离度量标准

   ![](\imgs\损失函数的距离度量标准.PNG)

   triplet损失策略通常用平方欧几里得距离。

#### 4. 预定义的度量标准，欧几里得距离

1. 学习目标：最小化相似物体的距离，最大化不同物体的距离

   ![](\imgs\神经网络的学习目标.PNG)

   ![](\imgs\欧几里得距离公式.PNG)
   
   **重要说明：其中的$i=j$表示$x^{i}$和$x^{j}$来自于同一个类别，否则表示不是同一个类别。**

#### 5. 学习到的度量标准，非线性距离度量标准

一个通用的策略是：从twin network中获得的输出向量会通过另外多个额外的网络层来实现非线性距离度量标准。

![](\imgs\siamese_学习的距离_非线性距离度量标准.PNG)

#### 6. 学习到的度量标准，half-twin网络

![](\imgs\siamese_learned metrics_half-twin networks.PNG)

#### 7. Siamese中的难理解点

* 什么是权值共享，为什么要进行权值共享，权值共享有必要吗？

   左右两个网络共享权值，**（目前我不知道权值共享存在的意义在哪里20200410）**

* 孪生神经网络的用途：目的就是通过训练来得到一个相似性距离度量标准，然后判断样本的相似性

* 整个网络的输入到底怎样表示才能更好的理解训练过程？

  如果是以pair对的方式,形如$(X_1,X_2)$来表示一组输入，那么可以得到相应的距离值，或者叫距离分数(score)。那么将所有的样本都以这样的pair对送入网络进行训练，通过网络的前向传播过程和反向传播过程，那么是可以获得符合某个识别任务的神经网络的模型的。

  **以上就已经阐释了孪生神经网络的训练过程。**

#### 8. Siamese网络结构图

**孪生神经网络(siamese network)**

![](\imgs\孪生神经网络结构.PNG)

**孪生神经网络另外一张图(带数学表示)**

![](\imgs\孪生神经网络结构_数学.PNG)

**伪孪生神经网络(pseudo-siamese network)**

两边可以是不同的神经网络(如左LSTM 右CNN)，也可以是相同类型的神经网络

![](\imgs\伪孪生神经网络.PNG)

#### 9. 孪生网络的损失函数怎么选

1. softmax
2. contrastive loss
3. cosine distance、exp function、欧式距离
4. 纯经验论: cosine适用于词汇级别的语义相似度度量；exp更适用于句子级别、段落级别的文本相似性度量

#### 10. 随便选取一个卷积神经网络来探究它的构建过程

![](\imgs\CNN卷积神经网络.PNG)

卷积计算后特征图(feature map)的尺寸计算公式：$\frac{n+2*p-k}{s}+1$，其中$n$表示输入的特征图的大小，$p$表示padding的大小,$k$表示卷积核的大小,$s$表示stride的大小。

由上面的卷积神经网络结构来看，从第一层输入来看，他的输入大小为105，卷积核的大小为10，输出的特征图的大小为96，那么可以根据上面的尺寸公式来推算出$p=1,s=1$。然后经过一个$2$x$2$的池化操作，所以得到$48$x$48$的特征图，然后再进行卷积操作得到$42$x$42$的特征图，其中$p=1,s=1$。之后再经过一层$2$x$2$池化操作，得到$21$x$21$的特征图，然后经过卷积运算得到$18$x$18$的特征图，其中$p=0,s=1$。之后再经过$2$x$2$的池化操作得到$9$x$9$的特征图，然后经过卷积运算得到$6$x$6$的特征图，其中$p=0,s=1$。之后将特征图中的元素值展开成一维向量，送入全连接层进行训练，最终通过sigmoid函数得到输出单元。

**如果将其前面的256@6x6的特征图进行展开的话应该是9216个单元才是，为什么其中全连接层的数量是4096？**

所以我猜测是中间经过了一定过程使得向量长度成为了4096,至于具体情况可以查阅相关论文的相关代码来查看其中的具体情况。

#### 11. Siamese Network稍微形象化的网络结构

![](\imgs\siamese network稍微形象化的网络结构.PNG)

#### 12. 孪生神经网络它到底是一个什么样的结构？它到底有什么优势？

![](\imgs\孪生神经网络结构_数学.PNG)

我们的最终目的就是学习到这么一个网络结构(孪生网络结构),这个结构能够使得最小化类内距离，最大化类间距离，详见《4.预定义的度量标准，欧几里得距离》。那么展现在上面的图结构中的$Distance=||G_W(X_1)-G_W(X_2)||$则是我们的距离目标。

**训练的最终目的就是，**针对训练集中的所有样本，当把同一个类别中的样本($X_1和X_2属于同一类$)送入到网络中，使得$Distance$最小，当把不是同一类别的样本($X_1和X_2属于不同类$)送入到网络中，使得$Distance$最大。

那么问题来了，最小化类内距离，最大化类间距离，这个标准是怎么来定？

第4点中明确告诉我们可以使用欧式距离来近似地表示样本与样本之间的距离。**所以问题就转化成了“如果要判断两个输入样本的相似性，那么只要计算他们的欧式距离就可以了，欧式距离越小，说明样本越相似，否则样本越不相似”**。

回到本文所询问的，孪生网络到底是个什么结构，很明显，根据上面的图就可以看出来：这是一个判断样本相似性的神经网络结构。

孪生网络的优势在哪里？**它只是用来对样本的相似性进行学习的!**

#### 13.卷积神经网络和孪生神经网络有什么关系

**前置疑问：**  卷积层是用来干什么的？ 卷积层就是通过对某一层的输入进行卷积运算，得到下一层结果(这个也叫做feature map)，简而言之就是 feature map的提取。

首先必须明确卷积神经网络的作用，如上面第10点所示卷积神经网络结构图，卷积神经网络可以对输入信号进行特征提取,后面再接一个全连接层，通过往网络上送入大量的带标签的训练样本，在初始化权重和偏置的情况下(一一般可以使用正态分布来初始化网络的权重系数和偏置系数，当然我们也可以从其他的相似性的学习任务上使用他们的权重系数和偏置系数，这个就是迁移过程，在此基础上的模型训练就叫做**迁移学习**)，得到一个输出向量和关于该网络对于这个样本的score值，以上的过程叫做**神经网络的正向传播过程**；然后网络的最终目的是$Loss$最小，需要对网络进行**反向传播(其实就是数学上的求梯度的过程)**。最终使得训练的网络的$Loss$尽可能得小(此时我们暂时认为通过上述训练的过程，我们已经得到了关于某个分类任务(假设是个分类任务)的比较好的网络模型)。

由第12点可以看到，孪生网络目的主要是学习到一个相似性距离函数而已，它的主干网络可以是任何形式的神经网络(比如说ResNet网络,LSTM网络，VGG网络)或者其他结构。所以孪生网络和卷积神经网络并没有特别大的联系。

#### 14.对于目标跟踪任务来说，Siamese Network有什么特别的优势？

**!!!!   暂不了解，先不予以讨论**

#### 15. 随便摘取一段代码：用Pytorch和Siamese Network来对MNIST图像进行分类，用作之后学习

```python
import codecs
import errno
import matplotlib.pyplot as plt
import numpy as np
import os
from PIL import Image
import random
import torch
from torch import nn
from torch import optim
import torch.nn.functional as F
import torchvision.datasets.mnist
from torchvision import transforms
from tqdm import tqdm

do_learn = True
save_frequency = 2
batch_size = 16
lr = 0.001
num_epochs = 10
weight_decay = 0.0001

def get_int(b):
   return int(codecs.encode(b, 'hex'), 16)

def read_label_file(path):
   with open(path, 'rb') as f:
      data = f.read()
   assert get_int(data[:4]) == 2049
   length = get_int(data[4:8])
   parsed = np.frombuffer(data, dtype=np.uint8, offset=8)
   return torch.from_numpy(parsed).view(length).long()

def read_image_file(path):
   with open(path, 'rb') as f:
      data = f.read()
   assert get_int(data[:4]) == 2051
   length = get_int(data[4:8])
   num_rows = get_int(data[8:12])
   num_cols = get_int(data[12:16])
   images = []
   parsed = np.frombuffer(data, dtype=np.uint8, offset=16)
   return torch.from_numpy(parsed).view(length, num_rows, num_cols)

class BalancedMNISTPair(torch.utils.data.Dataset):
   """Dataset that on each iteration provides two random pairs of
   MNIST images. One pair is of the same number (positive sample), one
   is of two different numbers (negative sample).
   """
   urls = [
      'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',
      'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',
      'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',
      'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',
   ]
   raw_folder = 'raw'
   processed_folder = 'processed'
   training_file = 'training.pt'
   test_file = 'test.pt'
   
   def __init__(self, root, train=True, transform=None, target_transform=None, download=False):
      self.root = os.path.expanduser(root)
      self.transform = transform
      self.target_transform = target_transform
      self.train = train # training set or test set
      
      if download:
         self.download()
         
      if not self._check_exists():
         raise RuntimeError('Dataset not found.' + ' You can use download=True to download it')
         
      if self.train:
         self.train_data, self.train_labels = torch.load(
            os.path.join(self.root, self.processed_folder, self.training_file))
         
         train_labels_class = []
         train_data_class = []
         for i in range(10):
            indices = torch.squeeze((self.train_labels == i).nonzero())
            train_labels_class.append(torch.index_select(self.train_labels, 0, indices))
            train_data_class.append(torch.index_select(self.train_data, 0, indices))
            
         # generate balanced pairs
         self.train_data = []
         self.train_labels = []
         lengths = [x.shape[0] for x in train_labels_class]
         for i in range(10):
            for j in range(500): # create 500 pairs
               rnd_cls = random.randint(0,8) # choose random class that is not the same class
               if rnd_cls >= i:
                  rnd_cls = rnd_cls + 1

               rnd_dist = random.randint(0, 100)
                  
               self.train_data.append(torch.stack([train_data_class[i][j], train_data_class[i][j+rnd_dist], train_data_class[rnd_cls][j]]))
               self.train_labels.append([1,0])

         self.train_data = torch.stack(self.train_data)
         self.train_labels = torch.tensor(self.train_labels)
               
      else:
         self.test_data, self.test_labels = torch.load(
            os.path.join(self.root, self.processed_folder, self.test_file))
         
         test_labels_class = []
         test_data_class = []
         for i in range(10):
            indices = torch.squeeze((self.test_labels == i).nonzero())
            test_labels_class.append(torch.index_select(self.test_labels, 0, indices))
            test_data_class.append(torch.index_select(self.test_data, 0, indices))
            
         # generate balanced pairs
         self.test_data = []
         self.test_labels = []
         lengths = [x.shape[0] for x in test_labels_class]
         for i in range(10):
            for j in range(500): # create 500 pairs
               rnd_cls = random.randint(0,8) # choose random class that is not the same class
               if rnd_cls >= i:
                  rnd_cls = rnd_cls + 1

               rnd_dist = random.randint(0, 100)
                  
               self.test_data.append(torch.stack([test_data_class[i][j], test_data_class[i][j+rnd_dist], test_data_class[rnd_cls][j]]))
               self.test_labels.append([1,0])

         self.test_data = torch.stack(self.test_data)
         self.test_labels = torch.tensor(self.test_labels)
         
   def __getitem__(self, index):
      if self.train:
         imgs, target = self.train_data[index], self.train_labels[index]
      else:
         imgs, target = self.test_data[index], self.test_labels[index]
         
      img_ar = []
      for i in range(len(imgs)):
         img = Image.fromarray(imgs[i].numpy(), mode='L')
         if self.transform is not None:
            img = self.transform(img)
         img_ar.append(img)
         
      if self.target_transform is not None:
         target = self.target_transform(target)
         
      return img_ar, target
   
   def __len__(self):
      if self.train:
         return len(self.train_data)
      else:
         return len(self.test_data)
      
   def _check_exists(self):
      return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \
         os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))
   
   def download(self):
      """Download the MNIST data if it doesn't exist in processed_folder already."""
      from six.moves import urllib
      import gzip

      if self._check_exists():
         return

      # download files
      try:
         os.makedirs(os.path.join(self.root, self.raw_folder))
         os.makedirs(os.path.join(self.root, self.processed_folder))
      except OSError as e:
         if e.errno == errno.EEXIST:
            pass
         else:
            raise

      for url in self.urls:
         print('Downloading ' + url)
         data = urllib.request.urlopen(url)
         filename = url.rpartition('/')[2]
         file_path = os.path.join(self.root, self.raw_folder, filename)
         with open(file_path, 'wb') as f:
            f.write(data.read())
         with open(file_path.replace('.gz', ''), 'wb') as out_f, \
               gzip.GzipFile(file_path) as zip_f:
            out_f.write(zip_f.read())
         os.unlink(file_path)

      # process and save as torch files
      print('Processing...')

      training_set = (
         read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),
         read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))
      )
      test_set = (
         read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),
         read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))
      )
      with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:
         torch.save(training_set, f)
      with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:
         torch.save(test_set, f)

      print('Done!')

   def __repr__(self):
      fmt_str = 'Dataset ' + self.__class__.__name__ + '\n'
      fmt_str += '    Number of datapoints: {}\n'.format(self.__len__())
      tmp = 'train' if self.train is True else 'test'
      fmt_str += '    Split: {}\n'.format(tmp)
      fmt_str += '    Root Location: {}\n'.format(self.root)
      tmp = '    Transforms (if any): '
      fmt_str += '{0}{1}\n'.format(tmp, self.transform.__repr__().replace('\n', '\n' + ' ' * len(tmp)))
      tmp = '    Target Transforms (if any): '
      fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\n', '\n' + ' ' * len(tmp)))
      return fmt_str
      
class Net(nn.Module):
   def __init__(self):
      super().__init__()
      
      self.conv1 = nn.Conv2d(1, 64, 7)
      self.pool1 = nn.MaxPool2d(2)
      self.conv2 = nn.Conv2d(64, 128, 5)
      self.conv3 = nn.Conv2d(128, 256, 5)
      self.linear1 = nn.Linear(2304, 512)
      
      self.linear2 = nn.Linear(512, 2)
      
   def forward(self, data):
      res = []
      for i in range(2): # Siamese nets; sharing weights
         x = data[i]
         x = self.conv1(x)
         x = F.relu(x)
         x = self.pool1(x)
         x = self.conv2(x)
         x = F.relu(x)
         x = self.conv3(x)
         x = F.relu(x)
         
         x = x.view(x.shape[0], -1)
         x = self.linear1(x)
         res.append(F.relu(x))
         
      res = torch.abs(res[1] - res[0])
      res = self.linear2(res)
      return res
   
def train(model, device, train_loader, epoch, optimizer):
   model.train()
   
   for batch_idx, (data, target) in enumerate(train_loader):
      for i in range(len(data)):
         data[i] = data[i].to(device)
         
      optimizer.zero_grad()
      output_positive = model(data[:2])
      output_negative = model(data[0:3:2])
      
      target = target.type(torch.LongTensor).to(device)
      target_positive = torch.squeeze(target[:,0])
      target_negative = torch.squeeze(target[:,1])
      
      loss_positive = F.cross_entropy(output_positive, target_positive)
      loss_negative = F.cross_entropy(output_negative, target_negative)
      
      loss = loss_positive + loss_negative
      loss.backward()
      
      optimizer.step()
      if batch_idx % 10 == 0:
         print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
            epoch, batch_idx*batch_size, len(train_loader.dataset), 100. * batch_idx*batch_size / len(train_loader.dataset),
            loss.item()))

def test(model, device, test_loader):
   model.eval()
   
   with torch.no_grad():
      accurate_labels = 0
      all_labels = 0
      loss = 0
      for batch_idx, (data, target) in enumerate(test_loader):
         for i in range(len(data)):
            data[i] = data[i].to(device)
            
         output_positive = model(data[:2])
         output_negative = model(data[0:3:2])
            
         target = target.type(torch.LongTensor).to(device)
         target_positive = torch.squeeze(target[:,0])
         target_negative = torch.squeeze(target[:,1])
            
         loss_positive = F.cross_entropy(output_positive, target_positive)
         loss_negative = F.cross_entropy(output_negative, target_negative)
            
         loss = loss + loss_positive + loss_negative
            
         accurate_labels_positive = torch.sum(torch.argmax(output_positive, dim=1) == target_positive).cpu()
         accurate_labels_negative = torch.sum(torch.argmax(output_negative, dim=1) == target_negative).cpu()
            
         accurate_labels = accurate_labels + accurate_labels_positive + accurate_labels_negative
         all_labels = all_labels + len(target_positive) + len(target_negative)
      
      accuracy = 100. * accurate_labels / all_labels
      print('Test accuracy: {}/{} ({:.3f}%)\tLoss: {:.6f}'.format(accurate_labels, all_labels, accuracy, loss))
   
def oneshot(model, device, data):
   model.eval()

   with torch.no_grad():
      for i in range(len(data)):
            data[i] = data[i].to(device)
      
      output = model(data)
      return torch.squeeze(torch.argmax(output, dim=1)).cpu().item()

def main():
   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
   trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])
   
   model = Net().to(device)
   
   if do_learn: # training mode
      train_loader = torch.utils.data.DataLoader(BalancedMNISTPair('../data', train=True, download=True, transform=trans), batch_size=batch_size, shuffle=True)
      test_loader = torch.utils.data.DataLoader(BalancedMNISTPair('../data', train=False, download=True, transform=trans), batch_size=batch_size, shuffle=False)
      
      optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
      for epoch in range(num_epochs):
         train(model, device, train_loader, epoch, optimizer)
         test(model, device, test_loader)
         if epoch & save_frequency == 0:
            torch.save(model, 'siamese_{:03}.pt'.format(epoch))
   else: # prediction
      prediction_loader = torch.utils.data.DataLoader(BalancedMNISTPair('../data', train=False, download=True, transform=trans), batch_size=1, shuffle=True)
      model.load_state_dict(torch.load(load_model_path))
      data = []
      data.extend(next(iter(prediction_loader))[0][:3:2])
      same = oneshot(model, device, data)
      if same > 0:
         print('These two images are of the same number')
      else:
         print('These two images are not of the same number')
         
if __name__ == '__main__':
   main()
```

